{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b44551e",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Hypothesis: We can use the https://arxiv.org/pdf/2406.04313 method for increasing honesty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198de680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T02:34:01.879987Z",
     "start_time": "2022-06-28T02:34:01.864103Z"
    }
   },
   "outputs": [],
   "source": [
    "# autoreload your package\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import adapter_overseer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d34518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a372ed7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T02:34:02.470436Z",
     "start_time": "2022-06-28T02:34:02.424826Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "# warnings.simplefilter(\"ignore\")\n",
    "# warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "# warnings.filterwarnings(\"ignore\", \".*divide by zero.*\")\n",
    "\n",
    "## numeric, plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (7.0, 4)\n",
    "\n",
    "## utils\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import logging, os, re\n",
    "import collections, functools, itertools\n",
    "from loguru import logger\n",
    "\n",
    "from typing import List, Callable, Tuple, Dict, Optional\n",
    "from jaxtyping import Float, Int\n",
    "from torch import Tensor\n",
    "\n",
    "# torch\n",
    "# import pytorch_lightning as pl\n",
    "from einops import rearrange, repeat, reduce\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from baukit.nethook import get_module\n",
    "from baukit import TraceDict\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64611cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtractConfig(datasets=('amazon_polarity',), datasets_ood='imdb', model='failspy/Llama-3-8B-Instruct-abliterated', collection_layers=('base_model.model.model.layers.10', 'base_model.model.model.layers.20'), batch_size=2, prompt_format=None, num_shots=2, max_length=776, max_examples=1000, seed=42, max_epochs=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adapter_overseer.config import ExtractConfig\n",
    "\n",
    "cfg = ExtractConfig()\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a03c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efd50635",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf63b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db1ee3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.bfloat16, device(type='cuda', index=0))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/blog/mlabonne/orpo-llama-3\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    !pip install -qqq flash-attn\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "    torch_dtype = torch.bfloat16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float16\n",
    "torch_dtype, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64890012",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T02:34:02.890216Z",
     "start_time": "2022-06-28T02:34:02.882249Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.60s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "# quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,     bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch_dtype, bnb_4bit_use_double_quant=True,)\n",
    "model = AutoModelForCausalLM.from_pretrained(cfg.model, device_map=\"auto\", quantization_config=quantization_config,)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f98e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.truncation_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "797d42af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|eot_id|>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://old.reddit.com/r/LocalLLaMA/comments/1coizjy/tokenizer_config_of_llama3_changed_by_meta_in_hf/\n",
    "tokenizer.eos_token # it's good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb24b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "# \\peft_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1\n",
    "# )\n",
    "# model = get_peft_model(model, peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b43d5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import prepare_model_for_int8_training\n",
    "# # we need to apply some post-processing on the 8-bit model to enable training, let's freeze all our layers, and cast the layer-norm in float32 for stability. We also cast the output of the last layer in float32 for the same reasons.\n",
    "# model = prepare_model_for_int8_training(model, output_embedding_layer_name=\"proj_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d4da6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 8,033,669,120 || trainable%: 0.0424\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model\n",
    "# https://github.com/huggingface/peft/blob/main/src/peft/utils/constants.py\n",
    "config = LoraConfig(\n",
    "                        #r=32, lora_alpha=64, \n",
    "                    # target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\"\n",
    "                    )\n",
    "\n",
    "\n",
    "# LoRA config\n",
    "# peft_config = LoraConfig(\n",
    "#     r=16,\n",
    "#     lora_alpha=32,\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "#     target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",
    "# )\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d102e3d",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0dd0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perhaps use load_preproc_datasets from sdb_probes_are_lie_detectors repo... /media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/src/prompts/prompt_loading.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c8ae82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 06:44:52.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36madapter_overseer.prompts.prompt_loading\u001b[0m:\u001b[36mload_preproc_dataset\u001b[0m:\u001b[36m392\u001b[0m - \u001b[1mmedian token length: 375.0 for amazon_polarity. max_length=776\u001b[0m\n",
      "\u001b[32m2024-06-10 06:44:52.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36madapter_overseer.prompts.prompt_loading\u001b[0m:\u001b[36mload_preproc_dataset\u001b[0m:\u001b[36m396\u001b[0m - \u001b[1mtruncation rate: 0.00% on amazon_polarity\u001b[0m\n",
      "/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2328: UserWarning: The groups parameter is ignored by StratifiedShuffleSplit\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-06-10 06:44:52.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36madapter_overseer.prompts.prompt_loading\u001b[0m:\u001b[36mload_preproc_dataset\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1mnum_rows (after filtering out truncated rows) 3004=>3004\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ds_string', 'example_i', 'answer', 'messages', 'answer_choices', 'template_name', 'label_true', 'label_instructed', 'instructed_to_lie', 'sys_instr_name', 'question', 'input_ids', 'attention_mask', 'truncated', 'length', 'prompt_truncated', 'choice_ids'],\n",
       "    num_rows: 1001\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a dataset of paired prompts, to try and get the model to lie\n",
    "from adapter_overseer.prompts.prompt_loading import load_preproc_datasets\n",
    "\n",
    "N = cfg.max_examples\n",
    "ds_tokens = load_preproc_datasets(\n",
    "    cfg.datasets,\n",
    "    tokenizer,\n",
    "    N=N,\n",
    "    seed=cfg.seed,\n",
    "    num_shots=cfg.num_shots,\n",
    "    max_length=cfg.max_length,\n",
    "    prompt_format=cfg.prompt_format,\n",
    ")\n",
    "ds_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e535a6d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eca812ab",
   "metadata": {},
   "source": [
    "## Train: transformers\n",
    "\n",
    "https://github.com/huggingface/peft/blob/main/examples/int8_training/Finetune_opt_bnb_peft.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "442bb987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "  1%|          | 11/2000 [04:02<12:09:38, 22.01s/it]\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-06-10 06:54:27.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 1, c: 2.499999936844688e-05, loss_rr: 0.988, loss_retain: 0.000, loss=0.988, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:54:33.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 1, c: 2.499999936844688e-05, loss_rr: 0.986, loss_retain: 0.000, loss=0.986, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 06:54:38.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 1, c: 2.499999936844688e-05, loss_rr: 0.993, loss_retain: 0.000, loss=0.993, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 06:54:44.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 1, c: 2.499999936844688e-05, loss_rr: 0.990, loss_retain: 0.000, loss=0.990, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 06:54:49.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 1, c: 2.499999936844688e-05, loss_rr: 0.988, loss_retain: 0.000, loss=0.988, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 06:54:55.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 1, c: 2.499999936844688e-05, loss_rr: 0.984, loss_retain: 0.000, loss=0.984, mask_desired: 0.500\u001b[0m\n",
      "  0%|          | 1/2000 [00:32<18:12:49, 32.80s/it]\n",
      "  0%|          | 1/2000 [00:32<18:12:49, 32.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9884, 'grad_norm': 0.06136675924062729, 'learning_rate': 2.9999999999999997e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 06:55:00.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 2, c: 4.999999873689376e-05, loss_rr: 0.988, loss_retain: 0.000, loss=0.988, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:55:06.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 2, c: 4.999999873689376e-05, loss_rr: 0.986, loss_retain: 0.000, loss=0.986, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:55:11.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 2, c: 4.999999873689376e-05, loss_rr: 0.986, loss_retain: 0.000, loss=0.986, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:55:17.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 2, c: 4.999999873689376e-05, loss_rr: 0.989, loss_retain: 0.000, loss=0.989, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:55:23.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 2, c: 4.999999873689376e-05, loss_rr: 0.985, loss_retain: 0.000, loss=0.985, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 06:55:28.750\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 2, c: 4.999999873689376e-05, loss_rr: 0.990, loss_retain: 0.000, loss=0.990, mask_desired: 0.750\u001b[0m\n",
      "  0%|          | 2/2000 [01:06<18:26:40, 33.23s/it]\n",
      "  0%|          | 2/2000 [01:06<18:26:40, 33.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9872, 'grad_norm': 0.06063719466328621, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 06:55:34.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 3, c: 7.500000356230885e-05, loss_rr: 0.988, loss_retain: 0.000, loss=0.987, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:55:40.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 3, c: 7.500000356230885e-05, loss_rr: 0.988, loss_retain: 0.000, loss=0.988, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 06:55:45.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 3, c: 7.500000356230885e-05, loss_rr: 0.000, loss_retain: 0.000, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 06:55:51.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 3, c: 7.500000356230885e-05, loss_rr: 0.978, loss_retain: 0.000, loss=0.978, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 06:55:56.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 3, c: 7.500000356230885e-05, loss_rr: 0.984, loss_retain: 0.000, loss=0.984, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:56:02.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 3, c: 7.500000356230885e-05, loss_rr: 0.984, loss_retain: 0.000, loss=0.984, mask_desired: 0.750\u001b[0m\n",
      "  0%|          | 3/2000 [01:40<18:34:05, 33.47s/it]\n",
      "  0%|          | 3/2000 [01:40<18:34:05, 33.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8202, 'grad_norm': 0.075690358877182, 'learning_rate': 8.999999999999999e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 06:56:08.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 4, c: 9.999999747378752e-05, loss_rr: 0.984, loss_retain: 0.000, loss=0.984, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 06:56:13.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 4, c: 9.999999747378752e-05, loss_rr: 0.982, loss_retain: 0.000, loss=0.982, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:56:19.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 4, c: 9.999999747378752e-05, loss_rr: 0.980, loss_retain: 0.000, loss=0.979, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 06:56:25.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 4, c: 9.999999747378752e-05, loss_rr: 0.000, loss_retain: 0.000, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 06:56:30.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 4, c: 9.999999747378752e-05, loss_rr: 0.978, loss_retain: 0.000, loss=0.978, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 06:56:36.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 4, c: 9.999999747378752e-05, loss_rr: 0.982, loss_retain: 0.000, loss=0.982, mask_desired: 0.500\u001b[0m\n",
      "  0%|          | 4/2000 [02:14<18:40:37, 33.69s/it]\n",
      "  0%|          | 4/2000 [02:14<18:40:37, 33.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8176, 'grad_norm': 0.08097293227910995, 'learning_rate': 0.00011999999999999999, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 06:56:42.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 5, c: 0.0001250000059371814, loss_rr: 0.961, loss_retain: 0.000, loss=0.961, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:56:47.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 5, c: 0.0001250000059371814, loss_rr: 0.956, loss_retain: 0.001, loss=0.955, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 06:56:53.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 5, c: 0.0001250000059371814, loss_rr: 0.962, loss_retain: 0.000, loss=0.962, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 06:56:59.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 5, c: 0.0001250000059371814, loss_rr: 0.955, loss_retain: 0.001, loss=0.955, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 06:57:04.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 5, c: 0.0001250000059371814, loss_rr: 0.965, loss_retain: 0.000, loss=0.964, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:57:10.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 5, c: 0.0001250000059371814, loss_rr: 0.953, loss_retain: 0.000, loss=0.953, mask_desired: 0.750\u001b[0m\n",
      "  0%|          | 5/2000 [02:48<18:43:55, 33.80s/it]\n",
      "  0%|          | 5/2000 [02:48<18:43:55, 33.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9584, 'grad_norm': 0.2663840353488922, 'learning_rate': 0.00015, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 06:57:16.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 6, c: 0.0001500000071246177, loss_rr: 0.942, loss_retain: 0.001, loss=0.942, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 06:57:21.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 6, c: 0.0001500000071246177, loss_rr: 0.930, loss_retain: 0.001, loss=0.930, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:57:27.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 6, c: 0.0001500000071246177, loss_rr: 0.000, loss_retain: 0.001, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 06:57:33.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 6, c: 0.0001500000071246177, loss_rr: 0.934, loss_retain: 0.001, loss=0.934, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:57:38.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 6, c: 0.0001500000071246177, loss_rr: 0.927, loss_retain: 0.001, loss=0.927, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:57:44.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 6, c: 0.0001500000071246177, loss_rr: 0.956, loss_retain: 0.000, loss=0.955, mask_desired: 0.000\u001b[0m\n",
      "  0%|          | 6/2000 [03:22<18:47:15, 33.92s/it]\n",
      "  0%|          | 6/2000 [03:22<18:47:15, 33.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7814, 'grad_norm': 0.33154547214508057, 'learning_rate': 0.00017999999999999998, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 06:57:50.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 7, c: 0.00017499999376013875, loss_rr: 0.905, loss_retain: 0.001, loss=0.905, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 06:57:56.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 7, c: 0.00017499999376013875, loss_rr: 0.000, loss_retain: 0.002, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 06:58:01.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 7, c: 0.00017499999376013875, loss_rr: 0.000, loss_retain: 0.003, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 06:58:07.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 7, c: 0.00017499999376013875, loss_rr: 0.890, loss_retain: 0.002, loss=0.890, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:58:13.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 7, c: 0.00017499999376013875, loss_rr: 0.910, loss_retain: 0.003, loss=0.910, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 06:58:18.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 7, c: 0.00017499999376013875, loss_rr: 0.888, loss_retain: 0.001, loss=0.888, mask_desired: 0.500\u001b[0m\n",
      "  0%|          | 7/2000 [03:56<18:49:56, 34.02s/it]\n",
      "  0%|          | 7/2000 [03:56<18:49:56, 34.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5987, 'grad_norm': 0.4056958854198456, 'learning_rate': 0.00020999999999999998, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 06:58:24.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 8, c: 0.00019999999494757503, loss_rr: 0.855, loss_retain: 0.006, loss=0.855, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:58:30.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 8, c: 0.00019999999494757503, loss_rr: 0.883, loss_retain: 0.005, loss=0.883, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 06:58:35.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 8, c: 0.00019999999494757503, loss_rr: 0.856, loss_retain: 0.005, loss=0.856, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 06:58:41.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 8, c: 0.00019999999494757503, loss_rr: 0.812, loss_retain: 0.005, loss=0.812, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 06:58:47.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 8, c: 0.00019999999494757503, loss_rr: 0.875, loss_retain: 0.005, loss=0.874, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 06:58:53.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 8, c: 0.00019999999494757503, loss_rr: 0.862, loss_retain: 0.005, loss=0.862, mask_desired: 0.750\u001b[0m\n",
      "  0%|          | 8/2000 [04:30<18:51:59, 34.10s/it]\n",
      "  0%|          | 8/2000 [04:30<18:51:59, 34.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8569, 'grad_norm': 0.6575590372085571, 'learning_rate': 0.00023999999999999998, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 06:58:58.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 9, c: 0.00022499999613501132, loss_rr: 0.827, loss_retain: 0.009, loss=0.827, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 06:59:04.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 9, c: 0.00022499999613501132, loss_rr: 0.728, loss_retain: 0.009, loss=0.728, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 06:59:10.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 9, c: 0.00022499999613501132, loss_rr: 0.786, loss_retain: 0.007, loss=0.786, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 06:59:16.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 9, c: 0.00022499999613501132, loss_rr: 0.738, loss_retain: 0.008, loss=0.738, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 06:59:21.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 9, c: 0.00022499999613501132, loss_rr: 0.815, loss_retain: 0.005, loss=0.815, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:59:27.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 9, c: 0.00022499999613501132, loss_rr: 0.802, loss_retain: 0.000, loss=0.801, mask_desired: 0.000\u001b[0m\n",
      "  0%|          | 9/2000 [05:05<18:54:58, 34.20s/it]\n",
      "  0%|          | 9/2000 [05:05<18:54:58, 34.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7825, 'grad_norm': 0.8301381468772888, 'learning_rate': 0.00027, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 06:59:33.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 10, c: 0.0002500000118743628, loss_rr: 0.713, loss_retain: 0.010, loss=0.713, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:59:38.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 10, c: 0.0002500000118743628, loss_rr: 0.740, loss_retain: 0.013, loss=0.740, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 06:59:44.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 10, c: 0.0002500000118743628, loss_rr: 0.752, loss_retain: 0.012, loss=0.752, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 06:59:50.451\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 10, c: 0.0002500000118743628, loss_rr: 0.720, loss_retain: 0.011, loss=0.720, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 06:59:56.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 10, c: 0.0002500000118743628, loss_rr: 0.743, loss_retain: 0.000, loss=0.743, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:00:01.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 10, c: 0.0002500000118743628, loss_rr: 0.733, loss_retain: 0.009, loss=0.733, mask_desired: 0.750\u001b[0m\n",
      "  0%|          | 10/2000 [05:39<18:56:43, 34.27s/it]\n",
      "  0%|          | 10/2000 [05:39<18:56:43, 34.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7335, 'grad_norm': 0.6981897354125977, 'learning_rate': 0.0003, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:00:07.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 11, c: 0.0002749999985098839, loss_rr: 0.000, loss_retain: 0.014, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:00:13.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 11, c: 0.0002749999985098839, loss_rr: 0.746, loss_retain: 0.011, loss=0.746, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:00:19.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 11, c: 0.0002749999985098839, loss_rr: 0.715, loss_retain: 0.013, loss=0.715, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:00:24.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 11, c: 0.0002749999985098839, loss_rr: 0.713, loss_retain: 0.010, loss=0.713, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:00:30.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 11, c: 0.0002749999985098839, loss_rr: 0.751, loss_retain: 0.007, loss=0.751, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:00:36.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 11, c: 0.0002749999985098839, loss_rr: 0.775, loss_retain: 0.012, loss=0.775, mask_desired: 0.500\u001b[0m\n",
      "  1%|          | 11/2000 [06:14<18:58:33, 34.35s/it]\n",
      "  1%|          | 11/2000 [06:14<18:58:33, 34.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6166, 'grad_norm': 0.4491898715496063, 'learning_rate': 0.0002998492462311557, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:00:42.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 12, c: 0.0003000000142492354, loss_rr: 0.723, loss_retain: 0.015, loss=0.723, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:00:47.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 12, c: 0.0003000000142492354, loss_rr: 0.701, loss_retain: 0.015, loss=0.701, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:00:53.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 12, c: 0.0003000000142492354, loss_rr: 0.689, loss_retain: 0.014, loss=0.689, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:00:59.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 12, c: 0.0003000000142492354, loss_rr: 0.746, loss_retain: 0.000, loss=0.746, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:01:05.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 12, c: 0.0003000000142492354, loss_rr: 0.652, loss_retain: 0.014, loss=0.652, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:01:10.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 12, c: 0.0003000000142492354, loss_rr: 0.709, loss_retain: 0.000, loss=0.709, mask_desired: 0.000\u001b[0m\n",
      "  1%|          | 12/2000 [06:48<18:59:54, 34.40s/it]\n",
      "  1%|          | 12/2000 [06:48<18:59:54, 34.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7031, 'grad_norm': 0.8454946875572205, 'learning_rate': 0.00029969849246231153, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:01:16.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 13, c: 0.00032500000088475645, loss_rr: 0.643, loss_retain: 0.018, loss=0.643, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:01:22.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 13, c: 0.00032500000088475645, loss_rr: 0.712, loss_retain: 0.015, loss=0.712, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:01:28.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 13, c: 0.00032500000088475645, loss_rr: 0.665, loss_retain: 0.011, loss=0.664, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:01:34.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 13, c: 0.00032500000088475645, loss_rr: 0.705, loss_retain: 0.012, loss=0.705, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:01:39.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 13, c: 0.00032500000088475645, loss_rr: 0.712, loss_retain: 0.011, loss=0.712, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:01:45.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 13, c: 0.00032500000088475645, loss_rr: 0.000, loss_retain: 0.016, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "  1%|          | 13/2000 [07:23<19:01:22, 34.47s/it]\n",
      "  1%|          | 13/2000 [07:23<19:01:22, 34.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5727, 'grad_norm': 0.6691225171089172, 'learning_rate': 0.0002995477386934673, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:01:51.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 14, c: 0.0003499999875202775, loss_rr: 0.617, loss_retain: 0.013, loss=0.617, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:01:57.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 14, c: 0.0003499999875202775, loss_rr: 0.634, loss_retain: 0.020, loss=0.634, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:02:02.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 14, c: 0.0003499999875202775, loss_rr: 0.710, loss_retain: 0.018, loss=0.710, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:02:08.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 14, c: 0.0003499999875202775, loss_rr: 0.740, loss_retain: 0.017, loss=0.739, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:02:14.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 14, c: 0.0003499999875202775, loss_rr: 0.623, loss_retain: 0.000, loss=0.623, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:02:20.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 14, c: 0.0003499999875202775, loss_rr: 0.689, loss_retain: 0.017, loss=0.688, mask_desired: 0.750\u001b[0m\n",
      "  1%|          | 14/2000 [07:57<19:02:28, 34.52s/it]\n",
      "  1%|          | 14/2000 [07:57<19:02:28, 34.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6686, 'grad_norm': 0.7955325245857239, 'learning_rate': 0.0002993969849246231, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:02:26.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 15, c: 0.000375000003259629, loss_rr: 0.681, loss_retain: 0.021, loss=0.681, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:02:31.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 15, c: 0.000375000003259629, loss_rr: 0.654, loss_retain: 0.020, loss=0.653, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:02:37.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 15, c: 0.000375000003259629, loss_rr: 0.660, loss_retain: 0.022, loss=0.660, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:02:43.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 15, c: 0.000375000003259629, loss_rr: 0.696, loss_retain: 0.017, loss=0.696, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:02:49.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 15, c: 0.000375000003259629, loss_rr: 0.000, loss_retain: 0.019, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:02:54.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 15, c: 0.000375000003259629, loss_rr: 0.641, loss_retain: 0.021, loss=0.641, mask_desired: 0.500\u001b[0m\n",
      "  1%|          | 15/2000 [08:32<19:02:23, 34.53s/it]\n",
      "  1%|          | 15/2000 [08:32<19:02:23, 34.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5551, 'grad_norm': 0.8235176801681519, 'learning_rate': 0.0002992462311557789, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:03:00.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 16, c: 0.00039999998989515007, loss_rr: 0.566, loss_retain: 0.021, loss=0.566, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:03:06.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 16, c: 0.00039999998989515007, loss_rr: 0.591, loss_retain: 0.024, loss=0.591, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:03:12.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 16, c: 0.00039999998989515007, loss_rr: 0.633, loss_retain: 0.024, loss=0.633, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:03:17.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 16, c: 0.00039999998989515007, loss_rr: 0.567, loss_retain: 0.025, loss=0.567, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:03:23.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 16, c: 0.00039999998989515007, loss_rr: 0.599, loss_retain: 0.017, loss=0.598, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:03:29.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 16, c: 0.00039999998989515007, loss_rr: 0.649, loss_retain: 0.022, loss=0.649, mask_desired: 0.500\u001b[0m\n",
      "  1%|          | 16/2000 [09:06<19:01:02, 34.51s/it]\n",
      "  1%|          | 16/2000 [09:06<19:01:02, 34.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6007, 'grad_norm': 1.1528459787368774, 'learning_rate': 0.00029909547738693465, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:03:35.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 17, c: 0.0004250000056345016, loss_rr: 0.562, loss_retain: 0.025, loss=0.562, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:03:40.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 17, c: 0.0004250000056345016, loss_rr: 0.524, loss_retain: 0.000, loss=0.524, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:03:46.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 17, c: 0.0004250000056345016, loss_rr: 0.499, loss_retain: 0.026, loss=0.498, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:03:52.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 17, c: 0.0004250000056345016, loss_rr: 0.553, loss_retain: 0.023, loss=0.553, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:03:58.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 17, c: 0.0004250000056345016, loss_rr: 0.511, loss_retain: 0.030, loss=0.511, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:04:03.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 17, c: 0.0004250000056345016, loss_rr: 0.573, loss_retain: 0.028, loss=0.573, mask_desired: 0.500\u001b[0m\n",
      "  1%|          | 17/2000 [09:41<19:00:46, 34.52s/it]\n",
      "  1%|          | 17/2000 [09:41<19:00:46, 34.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.537, 'grad_norm': 1.1799741983413696, 'learning_rate': 0.0002989447236180904, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:04:09.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 18, c: 0.00044999999227002263, loss_rr: 0.490, loss_retain: 0.031, loss=0.490, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:04:15.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 18, c: 0.00044999999227002263, loss_rr: 0.475, loss_retain: 0.033, loss=0.475, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:04:20.974\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 18, c: 0.00044999999227002263, loss_rr: 0.463, loss_retain: 0.034, loss=0.463, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:04:26.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 18, c: 0.00044999999227002263, loss_rr: 0.476, loss_retain: 0.030, loss=0.476, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:04:32.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 18, c: 0.00044999999227002263, loss_rr: 0.475, loss_retain: 0.032, loss=0.475, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:04:38.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 18, c: 0.00044999999227002263, loss_rr: 0.519, loss_retain: 0.031, loss=0.519, mask_desired: 0.500\u001b[0m\n",
      "  1%|          | 18/2000 [10:15<18:59:00, 34.48s/it]\n",
      "  1%|          | 18/2000 [10:15<18:59:00, 34.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4831, 'grad_norm': 1.3564367294311523, 'learning_rate': 0.0002987939698492462, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:04:43.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 19, c: 0.00047500000800937414, loss_rr: 0.448, loss_retain: 0.035, loss=0.448, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:04:49.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 19, c: 0.00047500000800937414, loss_rr: 0.473, loss_retain: 0.035, loss=0.473, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:04:55.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 19, c: 0.00047500000800937414, loss_rr: 0.423, loss_retain: 0.034, loss=0.423, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:05:01.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 19, c: 0.00047500000800937414, loss_rr: 0.477, loss_retain: 0.037, loss=0.477, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:05:06.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 19, c: 0.00047500000800937414, loss_rr: 0.447, loss_retain: 0.032, loss=0.447, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:05:12.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 19, c: 0.00047500000800937414, loss_rr: 0.446, loss_retain: 0.000, loss=0.446, mask_desired: 0.000\u001b[0m\n",
      "  1%|          | 19/2000 [10:50<18:57:58, 34.47s/it]\n",
      "  1%|          | 19/2000 [10:50<18:57:58, 34.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4521, 'grad_norm': 1.1842265129089355, 'learning_rate': 0.00029864321608040196, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:05:18.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 20, c: 0.0005000000237487257, loss_rr: 0.000, loss_retain: 0.038, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:05:24.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 20, c: 0.0005000000237487257, loss_rr: 0.428, loss_retain: 0.038, loss=0.428, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:05:29.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 20, c: 0.0005000000237487257, loss_rr: 0.427, loss_retain: 0.038, loss=0.426, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:05:35.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 20, c: 0.0005000000237487257, loss_rr: 0.420, loss_retain: 0.038, loss=0.420, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:05:41.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 20, c: 0.0005000000237487257, loss_rr: 0.463, loss_retain: 0.037, loss=0.462, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:05:47.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 20, c: 0.0005000000237487257, loss_rr: 0.439, loss_retain: 0.000, loss=0.439, mask_desired: 0.000\u001b[0m\n",
      "  1%|          | 20/2000 [11:24<18:56:49, 34.45s/it]\n",
      "  1%|          | 20/2000 [11:24<18:56:49, 34.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3625, 'grad_norm': 1.104626178741455, 'learning_rate': 0.00029849246231155777, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:05:52.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 21, c: 0.0005249999812804163, loss_rr: 0.401, loss_retain: 0.000, loss=0.400, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:05:58.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 21, c: 0.0005249999812804163, loss_rr: 0.411, loss_retain: 0.040, loss=0.410, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:06:04.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 21, c: 0.0005249999812804163, loss_rr: 0.427, loss_retain: 0.040, loss=0.427, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:06:09.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 21, c: 0.0005249999812804163, loss_rr: 0.399, loss_retain: 0.040, loss=0.399, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:06:15.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 21, c: 0.0005249999812804163, loss_rr: 0.418, loss_retain: 0.039, loss=0.418, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:06:21.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 21, c: 0.0005249999812804163, loss_rr: 0.449, loss_retain: 0.042, loss=0.449, mask_desired: 0.750\u001b[0m\n",
      "  1%|          | 21/2000 [11:59<18:55:40, 34.43s/it]\n",
      "  1%|          | 21/2000 [11:59<18:55:40, 34.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4172, 'grad_norm': 1.3811888694763184, 'learning_rate': 0.0002983417085427135, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:06:27.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 22, c: 0.0005499999970197678, loss_rr: 0.410, loss_retain: 0.041, loss=0.410, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:06:32.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 22, c: 0.0005499999970197678, loss_rr: 0.388, loss_retain: 0.042, loss=0.388, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:06:38.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 22, c: 0.0005499999970197678, loss_rr: 0.000, loss_retain: 0.041, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:06:44.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 22, c: 0.0005499999970197678, loss_rr: 0.402, loss_retain: 0.041, loss=0.402, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:06:50.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 22, c: 0.0005499999970197678, loss_rr: 0.391, loss_retain: 0.042, loss=0.391, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:06:55.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 22, c: 0.0005499999970197678, loss_rr: 0.377, loss_retain: 0.042, loss=0.377, mask_desired: 0.750\u001b[0m\n",
      "  1%|          | 22/2000 [12:33<18:54:40, 34.42s/it]\n",
      "  1%|          | 22/2000 [12:33<18:54:40, 34.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3279, 'grad_norm': 1.4486515522003174, 'learning_rate': 0.00029819095477386933, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:07:01.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 23, c: 0.0005750000127591193, loss_rr: 0.394, loss_retain: 0.044, loss=0.393, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:07:07.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 23, c: 0.0005750000127591193, loss_rr: 0.368, loss_retain: 0.044, loss=0.368, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:07:13.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 23, c: 0.0005750000127591193, loss_rr: 0.371, loss_retain: 0.043, loss=0.371, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:07:18.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 23, c: 0.0005750000127591193, loss_rr: 0.380, loss_retain: 0.046, loss=0.380, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:07:24.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 23, c: 0.0005750000127591193, loss_rr: 0.373, loss_retain: 0.046, loss=0.373, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:07:30.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 23, c: 0.0005750000127591193, loss_rr: 0.380, loss_retain: 0.042, loss=0.380, mask_desired: 0.250\u001b[0m\n",
      "  1%|          | 23/2000 [13:07<18:54:29, 34.43s/it]\n",
      "  1%|          | 23/2000 [13:07<18:54:29, 34.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3774, 'grad_norm': 1.7152425050735474, 'learning_rate': 0.00029804020100502514, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:07:36.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 24, c: 0.0006000000284984708, loss_rr: 0.354, loss_retain: 0.047, loss=0.354, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:07:41.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 24, c: 0.0006000000284984708, loss_rr: 0.373, loss_retain: 0.049, loss=0.373, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:07:47.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 24, c: 0.0006000000284984708, loss_rr: 0.367, loss_retain: 0.046, loss=0.367, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:07:53.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 24, c: 0.0006000000284984708, loss_rr: 0.365, loss_retain: 0.049, loss=0.364, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:07:59.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 24, c: 0.0006000000284984708, loss_rr: 0.359, loss_retain: 0.047, loss=0.359, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:08:04.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 24, c: 0.0006000000284984708, loss_rr: 0.361, loss_retain: 0.044, loss=0.361, mask_desired: 0.750\u001b[0m\n",
      "  1%|          | 24/2000 [13:42<18:55:59, 34.49s/it]\n",
      "  1%|          | 24/2000 [13:42<18:55:59, 34.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.363, 'grad_norm': 1.3496503829956055, 'learning_rate': 0.0002978894472361809, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:08:10.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 25, c: 0.0006249999860301614, loss_rr: 0.359, loss_retain: 0.052, loss=0.359, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:08:16.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 25, c: 0.0006249999860301614, loss_rr: 0.359, loss_retain: 0.051, loss=0.358, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:08:22.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 25, c: 0.0006249999860301614, loss_rr: 0.348, loss_retain: 0.050, loss=0.348, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:08:27.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 25, c: 0.0006249999860301614, loss_rr: 0.355, loss_retain: 0.051, loss=0.355, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:08:33.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 25, c: 0.0006249999860301614, loss_rr: 0.363, loss_retain: 0.049, loss=0.362, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:08:39.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 25, c: 0.0006249999860301614, loss_rr: 0.365, loss_retain: 0.050, loss=0.364, mask_desired: 0.750\u001b[0m\n",
      "  1%|▏         | 25/2000 [14:17<18:56:50, 34.54s/it]\n",
      "  1%|▏         | 25/2000 [14:17<18:56:50, 34.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3578, 'grad_norm': 1.3774548768997192, 'learning_rate': 0.00029773869346733664, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:08:45.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 26, c: 0.0006500000017695129, loss_rr: 0.346, loss_retain: 0.052, loss=0.346, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:08:51.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 26, c: 0.0006500000017695129, loss_rr: 0.344, loss_retain: 0.057, loss=0.344, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:08:56.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 26, c: 0.0006500000017695129, loss_rr: 0.345, loss_retain: 0.054, loss=0.345, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:09:02.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 26, c: 0.0006500000017695129, loss_rr: 0.331, loss_retain: 0.055, loss=0.330, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:09:08.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 26, c: 0.0006500000017695129, loss_rr: 0.340, loss_retain: 0.053, loss=0.340, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:09:14.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 26, c: 0.0006500000017695129, loss_rr: 0.331, loss_retain: 0.055, loss=0.331, mask_desired: 0.500\u001b[0m\n",
      "  1%|▏         | 26/2000 [14:51<18:57:04, 34.56s/it]\n",
      "  1%|▏         | 26/2000 [14:51<18:57:04, 34.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3394, 'grad_norm': 1.6528685092926025, 'learning_rate': 0.00029758793969849245, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:09:19.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 27, c: 0.0006750000175088644, loss_rr: 0.337, loss_retain: 0.056, loss=0.337, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:09:25.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 27, c: 0.0006750000175088644, loss_rr: 0.326, loss_retain: 0.055, loss=0.326, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:09:31.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 27, c: 0.0006750000175088644, loss_rr: 0.000, loss_retain: 0.056, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:09:37.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 27, c: 0.0006750000175088644, loss_rr: 0.348, loss_retain: 0.056, loss=0.348, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:09:42.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 27, c: 0.0006750000175088644, loss_rr: 0.329, loss_retain: 0.058, loss=0.329, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:09:48.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 27, c: 0.0006750000175088644, loss_rr: 0.000, loss_retain: 0.059, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "  1%|▏         | 27/2000 [15:26<18:56:46, 34.57s/it]\n",
      "  1%|▏         | 27/2000 [15:26<18:56:46, 34.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2232, 'grad_norm': 0.9091976881027222, 'learning_rate': 0.0002974371859296482, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:09:54.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 28, c: 0.000699999975040555, loss_rr: 0.318, loss_retain: 0.058, loss=0.318, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:10:00.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 28, c: 0.000699999975040555, loss_rr: 0.328, loss_retain: 0.059, loss=0.328, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:10:06.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 28, c: 0.000699999975040555, loss_rr: 0.329, loss_retain: 0.061, loss=0.328, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:10:11.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 28, c: 0.000699999975040555, loss_rr: 0.310, loss_retain: 0.000, loss=0.309, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:10:17.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 28, c: 0.000699999975040555, loss_rr: 0.322, loss_retain: 0.060, loss=0.322, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:10:23.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 28, c: 0.000699999975040555, loss_rr: 0.317, loss_retain: 0.058, loss=0.317, mask_desired: 0.750\u001b[0m\n",
      "  1%|▏         | 28/2000 [16:00<18:56:00, 34.56s/it]\n",
      "  1%|▏         | 28/2000 [16:00<18:56:00, 34.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3203, 'grad_norm': 1.7665152549743652, 'learning_rate': 0.000297286432160804, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:10:29.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 29, c: 0.0007249999907799065, loss_rr: 0.311, loss_retain: 0.059, loss=0.311, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:10:34.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 29, c: 0.0007249999907799065, loss_rr: 0.324, loss_retain: 0.059, loss=0.323, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:10:40.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 29, c: 0.0007249999907799065, loss_rr: 0.318, loss_retain: 0.060, loss=0.317, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:10:46.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 29, c: 0.0007249999907799065, loss_rr: 0.301, loss_retain: 0.060, loss=0.301, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:10:52.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 29, c: 0.0007249999907799065, loss_rr: 0.316, loss_retain: 0.058, loss=0.315, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:10:57.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 29, c: 0.0007249999907799065, loss_rr: 0.322, loss_retain: 0.059, loss=0.322, mask_desired: 0.500\u001b[0m\n",
      "  1%|▏         | 29/2000 [16:35<18:55:07, 34.55s/it]\n",
      "  1%|▏         | 29/2000 [16:35<18:55:07, 34.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.315, 'grad_norm': 2.5819449424743652, 'learning_rate': 0.00029713567839195976, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:11:03.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 30, c: 0.000750000006519258, loss_rr: 0.320, loss_retain: 0.061, loss=0.320, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:11:09.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 30, c: 0.000750000006519258, loss_rr: 0.315, loss_retain: 0.062, loss=0.314, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:11:15.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 30, c: 0.000750000006519258, loss_rr: 0.293, loss_retain: 0.062, loss=0.293, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:11:20.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 30, c: 0.000750000006519258, loss_rr: 0.305, loss_retain: 0.059, loss=0.305, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:11:26.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 30, c: 0.000750000006519258, loss_rr: 0.314, loss_retain: 0.059, loss=0.314, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:11:32.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 30, c: 0.000750000006519258, loss_rr: 0.298, loss_retain: 0.061, loss=0.298, mask_desired: 0.750\u001b[0m\n",
      "  2%|▏         | 30/2000 [17:10<18:54:13, 34.54s/it]\n",
      "  2%|▏         | 30/2000 [17:10<18:54:13, 34.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3073, 'grad_norm': 3.651921033859253, 'learning_rate': 0.0002969849246231155, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:11:38.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 31, c: 0.0007750000222586095, loss_rr: 0.314, loss_retain: 0.062, loss=0.314, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:11:43.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 31, c: 0.0007750000222586095, loss_rr: 0.291, loss_retain: 0.063, loss=0.291, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:11:49.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 31, c: 0.0007750000222586095, loss_rr: 0.302, loss_retain: 0.061, loss=0.302, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:11:55.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 31, c: 0.0007750000222586095, loss_rr: 0.292, loss_retain: 0.059, loss=0.292, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:12:01.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 31, c: 0.0007750000222586095, loss_rr: 0.320, loss_retain: 0.061, loss=0.320, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:12:06.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 31, c: 0.0007750000222586095, loss_rr: 0.302, loss_retain: 0.065, loss=0.302, mask_desired: 0.250\u001b[0m\n",
      "  2%|▏         | 31/2000 [17:44<18:53:59, 34.56s/it]\n",
      "  2%|▏         | 31/2000 [17:44<18:53:59, 34.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3034, 'grad_norm': 4.210335731506348, 'learning_rate': 0.0002968341708542713, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:12:12.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 32, c: 0.0007999999797903001, loss_rr: 0.297, loss_retain: 0.067, loss=0.297, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:12:18.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 32, c: 0.0007999999797903001, loss_rr: 0.297, loss_retain: 0.062, loss=0.297, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:12:24.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 32, c: 0.0007999999797903001, loss_rr: 0.301, loss_retain: 0.062, loss=0.301, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:12:29.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 32, c: 0.0007999999797903001, loss_rr: 0.291, loss_retain: 0.062, loss=0.291, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:12:35.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 32, c: 0.0007999999797903001, loss_rr: 0.280, loss_retain: 0.060, loss=0.280, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:12:41.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 32, c: 0.0007999999797903001, loss_rr: 0.300, loss_retain: 0.057, loss=0.300, mask_desired: 0.250\u001b[0m\n",
      "  2%|▏         | 32/2000 [18:19<18:54:00, 34.57s/it]\n",
      "  2%|▏         | 32/2000 [18:19<18:54:00, 34.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2942, 'grad_norm': 5.933142185211182, 'learning_rate': 0.00029668341708542713, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:12:47.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 33, c: 0.0008249999955296516, loss_rr: 0.283, loss_retain: 0.000, loss=0.283, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:12:53.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 33, c: 0.0008249999955296516, loss_rr: 0.287, loss_retain: 0.061, loss=0.287, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:12:58.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 33, c: 0.0008249999955296516, loss_rr: 0.296, loss_retain: 0.062, loss=0.295, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:13:04.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 33, c: 0.0008249999955296516, loss_rr: 0.291, loss_retain: 0.062, loss=0.291, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:13:10.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 33, c: 0.0008249999955296516, loss_rr: 0.290, loss_retain: 0.062, loss=0.289, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:13:16.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 33, c: 0.0008249999955296516, loss_rr: 0.306, loss_retain: 0.000, loss=0.306, mask_desired: 0.000\u001b[0m\n",
      "  2%|▏         | 33/2000 [18:53<18:53:49, 34.59s/it]\n",
      "  2%|▏         | 33/2000 [18:53<18:53:49, 34.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2917, 'grad_norm': 8.013928413391113, 'learning_rate': 0.0002965326633165829, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:13:21.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 34, c: 0.0008500000112690032, loss_rr: 0.283, loss_retain: 0.061, loss=0.283, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:13:27.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 34, c: 0.0008500000112690032, loss_rr: 0.281, loss_retain: 0.060, loss=0.281, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:13:33.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 34, c: 0.0008500000112690032, loss_rr: 0.280, loss_retain: 0.059, loss=0.280, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:13:39.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 34, c: 0.0008500000112690032, loss_rr: 0.274, loss_retain: 0.061, loss=0.274, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:13:44.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1msteps: 34, c: 0.0008500000112690032, loss_rr: 0.297, loss_retain: 0.062, loss=0.296, mask_desired: 0.250\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 107\u001b[0m\n\u001b[1;32m     87\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CustomSFTTrainer(\n\u001b[1;32m     88\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     89\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\u001b[39;00m\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    106\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# silence the warnings. Please re-enable for inference!\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:440\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 440\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/transformers/trainer.py:3250\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3248\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3250\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:2130\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2129\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[1;32m   2132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO change the loss function!\n",
    "# we need to modify the forward pass, so that it returns a different loss function\n",
    "# but to calculate this we will need to residuals now, and as they werre\n",
    "# loss_bad = mse(repr_current, repr_target)\n",
    "\n",
    "# from transformers import SFTTrainer\n",
    "from trl.trainer import SFTTrainer, SFTConfig\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from adapter_overseer.helpers.torch_helpers import clear_mem, switch\n",
    "from adapter_overseer.helpers.scores import select_choices\n",
    "\n",
    "class CustomSFTTrainer(SFTTrainer):\n",
    "    \"\"\"\n",
    "    Custom SFTTrainer that orthoganalizes the repr of bad examples, and retains good repr of examples\n",
    "\n",
    "    See: https://arxiv.org/pdf/2406.04313\n",
    "\n",
    "    args:\n",
    "        collection_layers: list of baukit layer names to collect\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, collection_layers: list, alpha=0.1, **kwargs):\n",
    "        super(CustomSFTTrainer, self).__init__(*args, **kwargs)\n",
    "        self.collection_layers = collection_layers\n",
    "        self.alpha = alpha\n",
    "        self.total_steps = self.args.max_steps\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):       \n",
    "\n",
    "        batch = {'input_ids': inputs['input_ids'], 'attention_mask': inputs['attention_mask']}\n",
    "\n",
    "        # collect the residuals of the model\n",
    "        with model.disable_adapter():\n",
    "            orig_outputs = model(**batch, output_hidden_states=True)\n",
    "        outputs = model(**batch, output_hidden_states=True)\n",
    "\n",
    "        def collect_hs(hidden_states):\n",
    "            \"\"\"The residual stream is the diff of the hs.\"\"\"\n",
    "            hs = [hidden_states[i] for i in self.collection_layers]\n",
    "            return rearrange(hs, 'l b t h -> b l t h').diff(1)\n",
    "\n",
    "        rep_adapt = collect_hs(outputs.hidden_states)\n",
    "        rep_orig = collect_hs(orig_outputs.hidden_states)\n",
    "\n",
    "        # so now we have a mixed batch of good and bad outputs\n",
    "        # get probs of each choice\n",
    "        # compare to labels to seperate into good and bad\n",
    "        choice_ids = inputs['choice_ids'].detach().cpu().long()\n",
    "        # label_instructed = inputs['label_true'] ^ inputs['instructed_to_lie']\n",
    "        label_true = inputs['label_true']\n",
    "\n",
    "        # does the underlying model get it right or wrong?\n",
    "        end_logits = orig_outputs[\"logits\"][:, -1]\n",
    "        probs = torch.softmax(end_logits, -1)\n",
    "        choice_probs = select_choices(probs, choice_ids).sum(2)\n",
    "        binary_ans = choice_probs[:, 1] / (choice_probs.sum(1) + 1e-12)\n",
    "        correct_truth_telling = switch(binary_ans, label_true)\n",
    "        # correct_instruction_following = switch(binary_ans, label_instructed)\n",
    "\n",
    "        mask_desired = correct_truth_telling>0.5\n",
    "\n",
    "\n",
    "        # get coeffecient\n",
    "        steps = self.state.global_step + 1\n",
    "        c = torch.tensor(self.alpha * steps / (2 * self.total_steps)).to(rep_orig.dtype)\n",
    "        loss_retain = F.mse_loss(rep_orig, rep_adapt, reduction='none' )[mask_desired]\n",
    "        if loss_retain.numel() == 0:\n",
    "            loss_retain = 0\n",
    "        else:\n",
    "            loss_retain = loss_retain.mean()\n",
    "        loss_rr = F.relu(F.cosine_similarity(rep_orig, rep_adapt, dim=1))[~mask_desired]\n",
    "        if loss_rr.numel() == 0:\n",
    "            loss_rr = 0\n",
    "        else:\n",
    "            loss_rr = loss_rr.mean()\n",
    "        loss = loss_rr * (1 - c) + c * loss_retain\n",
    "        loss = loss\n",
    "        logger.debug(f\"steps: {steps}, c: {c}, loss_rr: {loss_rr:2.3f}, loss_retain: {loss_retain:2.3f}, loss={loss:2.3f}, mask_desired: {(mask_desired*1.0).mean():2.3f}\")\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "\n",
    "# TODO make sure that multiple cols get passed into trainer\n",
    "ds = ds_tokens.select_columns(['label_true', 'label_instructed' ,'instructed_to_lie', 'input_ids', 'attention_mask', 'choice_ids'])\n",
    "\n",
    "import transformers\n",
    "\n",
    "# see https://github.com/huggingface/trl/blob/main/trl/trainer/sft_trainer.py#L58\n",
    "trainer = CustomSFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=ds,\n",
    "    collection_layers=[10, 20],\n",
    "    # max_seq_length=cfg.max_length,\n",
    "    args=SFTConfig(\n",
    "        # see https://github.com/huggingface/trl/blob/main/trl/trainer/sft_config.py#L21\n",
    "        max_seq_length=cfg.max_length,\n",
    "        per_device_train_batch_size=4, # 18GB/24GB\n",
    "        gradient_accumulation_steps=6, # we want to accumulate the gradients to make the batch size larger, so we have sufficient examples of good and bad behaviour to learn from\n",
    "        warmup_steps=10,\n",
    "        max_steps=2000,\n",
    "        learning_rate=3e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        output_dir=\"outputs\",\n",
    "        remove_unused_columns=False,\n",
    "    ),\n",
    "    # data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b0cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "model.save_pretrained(\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec82d4d8",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d383d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import pipeline\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "input_texts = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")[\"text\"]\n",
    "input_texts = [s for s in input_texts[:200] if s!='']\n",
    "\n",
    "def preprocess_function(examples):\n",
    "\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "# https://huggingface.co/docs/transformers/v4.41.3/en/main_classes/pipelines#pipeline-batching\n",
    "batch_size = 4\n",
    "pipe = pipeline(\"text-classification\", device=\"auto\", model=model, tokenizer=tokenizer)\n",
    "    for out in tqdm(pipe(dataset, batch_size=batch_size), total=len(dataset)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4003d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
