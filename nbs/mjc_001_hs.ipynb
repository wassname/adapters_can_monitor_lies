{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b44551e",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Hypothesis: We can use the https://arxiv.org/pdf/2406.04313 method for increasing honesty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198de680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T02:34:01.879987Z",
     "start_time": "2022-06-28T02:34:01.864103Z"
    }
   },
   "outputs": [],
   "source": [
    "# autoreload your package\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import adapter_overseer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d34518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a372ed7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T02:34:02.470436Z",
     "start_time": "2022-06-28T02:34:02.424826Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "# warnings.simplefilter(\"ignore\")\n",
    "# warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "# warnings.filterwarnings(\"ignore\", \".*divide by zero.*\")\n",
    "\n",
    "## numeric, plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (7.0, 4)\n",
    "\n",
    "## utils\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import logging, os, re\n",
    "import collections, functools, itertools\n",
    "from loguru import logger\n",
    "\n",
    "from typing import List, Callable, Tuple, Dict, Optional\n",
    "from jaxtyping import Float, Int\n",
    "from torch import Tensor\n",
    "\n",
    "# torch\n",
    "# import pytorch_lightning as pl\n",
    "from einops import rearrange, repeat, reduce\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from baukit.nethook import get_module\n",
    "from baukit import TraceDict\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64611cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtractConfig(datasets=('amazon_polarity',), datasets_ood='imdb', model='failspy/Llama-3-8B-Instruct-abliterated', collection_layers=('base_model.model.model.layers.10', 'base_model.model.model.layers.20'), batch_size=2, prompt_format=None, num_shots=2, max_length=776, max_examples=1000, seed=42, max_epochs=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adapter_overseer.config import ExtractConfig\n",
    "\n",
    "cfg = ExtractConfig()\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a03c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efd50635",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf63b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db1ee3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.bfloat16, device(type='cuda', index=0))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/blog/mlabonne/orpo-llama-3\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    !pip install -qqq flash-attn\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "    torch_dtype = torch.bfloat16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float16\n",
    "torch_dtype, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64890012",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T02:34:02.890216Z",
     "start_time": "2022-06-28T02:34:02.882249Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "# quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,     bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch_dtype, bnb_4bit_use_double_quant=True,)\n",
    "model = AutoModelForCausalLM.from_pretrained(cfg.model, device_map=\"auto\", quantization_config=quantization_config,)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f98e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.truncation_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "797d42af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|eot_id|>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://old.reddit.com/r/LocalLLaMA/comments/1coizjy/tokenizer_config_of_llama3_changed_by_meta_in_hf/\n",
    "tokenizer.eos_token # it's good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb24b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "# \\peft_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1\n",
    "# )\n",
    "# model = get_peft_model(model, peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b43d5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import prepare_model_for_int8_training\n",
    "# # we need to apply some post-processing on the 8-bit model to enable training, let's freeze all our layers, and cast the layer-norm in float32 for stability. We also cast the output of the last layer in float32 for the same reasons.\n",
    "# model = prepare_model_for_int8_training(model, output_embedding_layer_name=\"proj_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d4da6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 8,033,669,120 || trainable%: 0.0424\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model\n",
    "# https://github.com/huggingface/peft/blob/main/src/peft/utils/constants.py\n",
    "config = LoraConfig(\n",
    "                        #r=32, lora_alpha=64, \n",
    "                    # target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\"\n",
    "                    )\n",
    "\n",
    "\n",
    "# LoRA config\n",
    "# peft_config = LoraConfig(\n",
    "#     r=16,\n",
    "#     lora_alpha=32,\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "#     target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",
    "# )\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "with model.disable_adapter():\n",
    "    model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d102e3d",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0dd0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perhaps use load_preproc_datasets from sdb_probes_are_lie_detectors repo... /media/wassname/SGIronWolf/projects5/elk/sgd_probes_are_lie_detectors/src/prompts/prompt_loading.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c8ae82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:40:28.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36madapter_overseer.prompts.prompt_loading\u001b[0m:\u001b[36mload_preproc_dataset\u001b[0m:\u001b[36m392\u001b[0m - \u001b[1mmedian token length: 375.0 for amazon_polarity. max_length=776\u001b[0m\n",
      "\u001b[32m2024-06-10 07:40:28.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36madapter_overseer.prompts.prompt_loading\u001b[0m:\u001b[36mload_preproc_dataset\u001b[0m:\u001b[36m396\u001b[0m - \u001b[1mtruncation rate: 0.00% on amazon_polarity\u001b[0m\n",
      "/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2328: UserWarning: The groups parameter is ignored by StratifiedShuffleSplit\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-06-10 07:40:28.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36madapter_overseer.prompts.prompt_loading\u001b[0m:\u001b[36mload_preproc_dataset\u001b[0m:\u001b[36m405\u001b[0m - \u001b[1mnum_rows (after filtering out truncated rows) 3004=>3004\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ds_string', 'example_i', 'answer', 'messages', 'answer_choices', 'template_name', 'label_true', 'label_instructed', 'instructed_to_lie', 'sys_instr_name', 'question', 'input_ids', 'attention_mask', 'truncated', 'length', 'prompt_truncated', 'choice_ids'],\n",
       "    num_rows: 1001\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a dataset of paired prompts, to try and get the model to lie\n",
    "from adapter_overseer.prompts.prompt_loading import load_preproc_datasets\n",
    "\n",
    "N = cfg.max_examples\n",
    "ds_tokens = load_preproc_datasets(\n",
    "    cfg.datasets,\n",
    "    tokenizer,\n",
    "    N=N,\n",
    "    seed=cfg.seed,\n",
    "    num_shots=cfg.num_shots,\n",
    "    max_length=cfg.max_length,\n",
    "    prompt_format=cfg.prompt_format,\n",
    ")\n",
    "ds_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e535a6d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eca812ab",
   "metadata": {},
   "source": [
    "## Train: transformers\n",
    "\n",
    "https://github.com/huggingface/peft/blob/main/examples/int8_training/Finetune_opt_bnb_peft.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "442bb987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-06-10 07:40:31.910\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 1, c: 2.499999936844688e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:40:37.111\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 1, c: 2.499999936844688e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:40:42.259\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 1, c: 2.499999936844688e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:40:47.427\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 1, c: 2.499999936844688e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:40:52.619\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 1, c: 2.499999936844688e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:40:57.801\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 1, c: 2.499999936844688e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "  0%|          | 1/2000 [00:31<17:21:47, 31.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0, 'grad_norm': 3.3594227399902366e-10, 'learning_rate': 2.9999999999999997e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:41:03.040\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 2, c: 4.999999873689376e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:41:08.245\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 2, c: 4.999999873689376e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:41:13.463\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 2, c: 4.999999873689376e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:41:18.703\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 2, c: 4.999999873689376e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:41:23.954\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 2, c: 4.999999873689376e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:41:29.223\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 2, c: 4.999999873689376e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.750\u001b[0m\n",
      "  0%|          | 2/2000 [01:02<17:24:25, 31.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0, 'grad_norm': 6.474682595625225e-11, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:41:34.526\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 3, c: 7.500000356230885e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:41:39.828\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 3, c: 7.500000356230885e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:41:45.140\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 3, c: 7.500000356230885e-05, loss_rr: 0.000, loss_retain: 0.000, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:41:50.460\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 3, c: 7.500000356230885e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:41:55.798\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 3, c: 7.500000356230885e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:42:01.164\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 3, c: 7.500000356230885e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.750\u001b[0m\n",
      "  0%|          | 3/2000 [01:34<17:33:05, 31.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8333, 'grad_norm': 2.1183223231080461e-10, 'learning_rate': 8.999999999999999e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:42:06.528\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 4, c: 9.999999747378752e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:42:11.895\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 4, c: 9.999999747378752e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:42:17.270\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 4, c: 9.999999747378752e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:42:22.657\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 4, c: 9.999999747378752e-05, loss_rr: 0.000, loss_retain: 0.000, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:42:28.052\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 4, c: 9.999999747378752e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:42:33.450\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 4, c: 9.999999747378752e-05, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "  0%|          | 4/2000 [02:06<17:41:29, 31.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8332, 'grad_norm': 1.373788721670266e-10, 'learning_rate': 0.00011999999999999999, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:42:38.864\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 5, c: 0.0001250000059371814, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:42:44.278\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 5, c: 0.0001250000059371814, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:42:49.698\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 5, c: 0.0001250000059371814, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:42:55.125\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 5, c: 0.0001250000059371814, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:43:00.554\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 5, c: 0.0001250000059371814, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:43:05.991\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 5, c: 0.0001250000059371814, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.750\u001b[0m\n",
      "  0%|          | 5/2000 [02:39<17:48:55, 32.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9999, 'grad_norm': 1.1267461269559575e-10, 'learning_rate': 0.00015, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:43:11.459\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 6, c: 0.0001500000071246177, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:43:16.900\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 6, c: 0.0001500000071246177, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:43:22.371\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 6, c: 0.0001500000071246177, loss_rr: 0.000, loss_retain: 0.000, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:43:27.821\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 6, c: 0.0001500000071246177, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:43:33.290\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 6, c: 0.0001500000071246177, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:43:38.769\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 6, c: 0.0001500000071246177, loss_rr: 1.000, loss_retain: 0.000, loss=1.000, mask_desired: 0.000\u001b[0m\n",
      "  0%|          | 6/2000 [03:12<17:55:27, 32.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8332, 'grad_norm': 0.00090835802257061, 'learning_rate': 0.00017999999999999998, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:43:44.245\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 7, c: 0.00017499999376013875, loss_rr: 1.000, loss_retain: 0.000, loss=0.999, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:43:49.766\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 7, c: 0.00017499999376013875, loss_rr: 0.000, loss_retain: 0.000, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:43:55.238\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 7, c: 0.00017499999376013875, loss_rr: 0.000, loss_retain: 0.000, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:44:00.712\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 7, c: 0.00017499999376013875, loss_rr: 0.999, loss_retain: 0.000, loss=0.999, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:44:06.232\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 7, c: 0.00017499999376013875, loss_rr: 0.999, loss_retain: 0.000, loss=0.999, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:44:11.740\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 7, c: 0.00017499999376013875, loss_rr: 1.000, loss_retain: 0.000, loss=0.999, mask_desired: 0.500\u001b[0m\n",
      "  0%|          | 7/2000 [03:45<18:02:01, 32.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6662, 'grad_norm': 0.004503950010985136, 'learning_rate': 0.00020999999999999998, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:44:17.276\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 8, c: 0.00019999999494757503, loss_rr: 0.999, loss_retain: 0.000, loss=0.999, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:44:22.809\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 8, c: 0.00019999999494757503, loss_rr: 0.999, loss_retain: 0.000, loss=0.999, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:44:28.327\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 8, c: 0.00019999999494757503, loss_rr: 0.999, loss_retain: 0.000, loss=0.999, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:44:33.882\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 8, c: 0.00019999999494757503, loss_rr: 0.998, loss_retain: 0.000, loss=0.998, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:44:39.405\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 8, c: 0.00019999999494757503, loss_rr: 0.999, loss_retain: 0.000, loss=0.999, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:44:44.968\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 8, c: 0.00019999999494757503, loss_rr: 0.999, loss_retain: 0.000, loss=0.999, mask_desired: 0.750\u001b[0m\n",
      "  0%|          | 8/2000 [04:18<18:08:20, 32.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9986, 'grad_norm': 0.004739789757877588, 'learning_rate': 0.00023999999999999998, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:44:50.500\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 9, c: 0.00022499999613501132, loss_rr: 0.996, loss_retain: 0.000, loss=0.996, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:44:56.058\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 9, c: 0.00022499999613501132, loss_rr: 0.994, loss_retain: 0.000, loss=0.994, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:45:01.579\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 9, c: 0.00022499999613501132, loss_rr: 0.994, loss_retain: 0.000, loss=0.994, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:45:07.183\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 9, c: 0.00022499999613501132, loss_rr: 0.994, loss_retain: 0.000, loss=0.993, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:45:12.755\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 9, c: 0.00022499999613501132, loss_rr: 0.997, loss_retain: 0.000, loss=0.996, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:45:18.317\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 9, c: 0.00022499999613501132, loss_rr: 0.996, loss_retain: 0.000, loss=0.996, mask_desired: 0.000\u001b[0m\n",
      "  0%|          | 9/2000 [04:51<18:14:13, 32.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9948, 'grad_norm': 0.01964593306183815, 'learning_rate': 0.00027, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:45:23.903\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 10, c: 0.0002500000118743628, loss_rr: 0.983, loss_retain: 0.000, loss=0.982, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:45:29.476\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 10, c: 0.0002500000118743628, loss_rr: 0.982, loss_retain: 0.000, loss=0.982, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:45:35.069\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 10, c: 0.0002500000118743628, loss_rr: 0.988, loss_retain: 0.000, loss=0.988, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:45:40.662\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 10, c: 0.0002500000118743628, loss_rr: 0.981, loss_retain: 0.000, loss=0.981, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:45:46.282\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 10, c: 0.0002500000118743628, loss_rr: 0.985, loss_retain: 0.000, loss=0.985, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:45:51.891\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 10, c: 0.0002500000118743628, loss_rr: 0.981, loss_retain: 0.000, loss=0.981, mask_desired: 0.750\u001b[0m\n",
      "  0%|          | 10/2000 [05:25<18:19:30, 33.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9831, 'grad_norm': 0.0802963376045227, 'learning_rate': 0.0003, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:45:57.468\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 11, c: 0.0002749999985098839, loss_rr: 0.000, loss_retain: 0.001, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:46:03.022\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 11, c: 0.0002749999985098839, loss_rr: 0.959, loss_retain: 0.000, loss=0.959, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:46:08.617\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 11, c: 0.0002749999985098839, loss_rr: 0.953, loss_retain: 0.001, loss=0.953, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:46:14.212\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 11, c: 0.0002749999985098839, loss_rr: 0.950, loss_retain: 0.000, loss=0.950, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:46:19.806\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 11, c: 0.0002749999985098839, loss_rr: 0.967, loss_retain: 0.000, loss=0.966, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:46:25.403\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 11, c: 0.0002749999985098839, loss_rr: 0.975, loss_retain: 0.001, loss=0.974, mask_desired: 0.500\u001b[0m\n",
      "  1%|          | 11/2000 [05:59<18:22:53, 33.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8004, 'grad_norm': 0.17458520829677582, 'learning_rate': 0.0002998492462311557, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:46:31.012\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 12, c: 0.0003000000142492354, loss_rr: 0.902, loss_retain: 0.004, loss=0.902, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:46:36.608\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 12, c: 0.0003000000142492354, loss_rr: 0.905, loss_retain: 0.004, loss=0.904, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:46:42.218\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 12, c: 0.0003000000142492354, loss_rr: 0.875, loss_retain: 0.003, loss=0.874, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:46:47.814\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 12, c: 0.0003000000142492354, loss_rr: 0.909, loss_retain: 0.000, loss=0.909, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:46:53.437\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 12, c: 0.0003000000142492354, loss_rr: 0.827, loss_retain: 0.002, loss=0.827, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:46:59.037\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 12, c: 0.0003000000142492354, loss_rr: 0.897, loss_retain: 0.000, loss=0.897, mask_desired: 0.000\u001b[0m\n",
      "  1%|          | 12/2000 [06:32<18:26:13, 33.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8855, 'grad_norm': 0.4783974289894104, 'learning_rate': 0.00029969849246231153, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:47:04.672\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 13, c: 0.00032500000088475645, loss_rr: 0.805, loss_retain: 0.007, loss=0.805, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:47:10.293\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 13, c: 0.00032500000088475645, loss_rr: 0.851, loss_retain: 0.006, loss=0.850, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:47:15.901\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 13, c: 0.00032500000088475645, loss_rr: 0.830, loss_retain: 0.004, loss=0.830, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:47:21.533\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 13, c: 0.00032500000088475645, loss_rr: 0.841, loss_retain: 0.004, loss=0.840, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:47:27.156\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 13, c: 0.00032500000088475645, loss_rr: 0.856, loss_retain: 0.004, loss=0.856, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:47:32.788\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 13, c: 0.00032500000088475645, loss_rr: 0.000, loss_retain: 0.006, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "  1%|          | 13/2000 [07:06<18:28:59, 33.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6971, 'grad_norm': 0.49628111720085144, 'learning_rate': 0.0002995477386934673, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:47:38.393\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 14, c: 0.0003499999875202775, loss_rr: 0.759, loss_retain: 0.007, loss=0.759, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:47:44.016\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 14, c: 0.0003499999875202775, loss_rr: 0.751, loss_retain: 0.010, loss=0.751, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:47:49.643\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 14, c: 0.0003499999875202775, loss_rr: 0.829, loss_retain: 0.009, loss=0.828, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:47:55.258\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 14, c: 0.0003499999875202775, loss_rr: 0.858, loss_retain: 0.010, loss=0.857, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:48:00.890\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 14, c: 0.0003499999875202775, loss_rr: 0.759, loss_retain: 0.000, loss=0.759, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:48:06.530\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 14, c: 0.0003499999875202775, loss_rr: 0.803, loss_retain: 0.010, loss=0.802, mask_desired: 0.750\u001b[0m\n",
      "  1%|          | 14/2000 [07:40<18:31:11, 33.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7928, 'grad_norm': 0.48608410358428955, 'learning_rate': 0.0002993969849246231, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:48:12.157\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 15, c: 0.000375000003259629, loss_rr: 0.816, loss_retain: 0.012, loss=0.816, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:48:17.778\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 15, c: 0.000375000003259629, loss_rr: 0.778, loss_retain: 0.012, loss=0.778, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:48:23.402\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 15, c: 0.000375000003259629, loss_rr: 0.782, loss_retain: 0.014, loss=0.782, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:48:29.031\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 15, c: 0.000375000003259629, loss_rr: 0.810, loss_retain: 0.010, loss=0.809, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:48:34.663\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 15, c: 0.000375000003259629, loss_rr: 0.000, loss_retain: 0.011, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:48:40.324\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 15, c: 0.000375000003259629, loss_rr: 0.775, loss_retain: 0.012, loss=0.775, mask_desired: 0.500\u001b[0m\n",
      "  1%|          | 15/2000 [08:14<18:32:57, 33.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6599, 'grad_norm': 0.508230447769165, 'learning_rate': 0.0002992462311557789, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:48:45.966\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 16, c: 0.00039999998989515007, loss_rr: 0.715, loss_retain: 0.012, loss=0.715, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:48:51.602\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 16, c: 0.00039999998989515007, loss_rr: 0.764, loss_retain: 0.014, loss=0.764, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:48:57.228\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 16, c: 0.00039999998989515007, loss_rr: 0.775, loss_retain: 0.014, loss=0.775, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:49:02.859\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 16, c: 0.00039999998989515007, loss_rr: 0.717, loss_retain: 0.015, loss=0.717, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:49:08.498\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 16, c: 0.00039999998989515007, loss_rr: 0.746, loss_retain: 0.008, loss=0.746, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:49:14.129\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 16, c: 0.00039999998989515007, loss_rr: 0.786, loss_retain: 0.012, loss=0.786, mask_desired: 0.500\u001b[0m\n",
      "  1%|          | 16/2000 [08:47<18:34:01, 33.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7503, 'grad_norm': 0.5595538020133972, 'learning_rate': 0.00029909547738693465, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:49:19.773\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 17, c: 0.0004250000056345016, loss_rr: 0.743, loss_retain: 0.013, loss=0.742, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:49:25.408\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 17, c: 0.0004250000056345016, loss_rr: 0.706, loss_retain: 0.000, loss=0.706, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:49:31.061\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 17, c: 0.0004250000056345016, loss_rr: 0.685, loss_retain: 0.013, loss=0.685, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:49:36.706\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 17, c: 0.0004250000056345016, loss_rr: 0.749, loss_retain: 0.010, loss=0.748, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:49:42.342\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 17, c: 0.0004250000056345016, loss_rr: 0.700, loss_retain: 0.017, loss=0.700, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:49:48.004\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 17, c: 0.0004250000056345016, loss_rr: 0.754, loss_retain: 0.016, loss=0.754, mask_desired: 0.500\u001b[0m\n",
      "  1%|          | 17/2000 [09:21<18:35:19, 33.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7224, 'grad_norm': 0.5684277415275574, 'learning_rate': 0.0002989447236180904, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:49:53.643\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 18, c: 0.00044999999227002263, loss_rr: 0.715, loss_retain: 0.012, loss=0.715, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:49:59.290\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 18, c: 0.00044999999227002263, loss_rr: 0.673, loss_retain: 0.018, loss=0.673, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:50:04.930\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 18, c: 0.00044999999227002263, loss_rr: 0.677, loss_retain: 0.017, loss=0.677, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:50:10.581\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 18, c: 0.00044999999227002263, loss_rr: 0.691, loss_retain: 0.012, loss=0.691, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:50:16.217\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 18, c: 0.00044999999227002263, loss_rr: 0.675, loss_retain: 0.013, loss=0.675, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:50:21.861\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 18, c: 0.00044999999227002263, loss_rr: 0.739, loss_retain: 0.014, loss=0.738, mask_desired: 0.500\u001b[0m\n",
      "  1%|          | 18/2000 [09:55<18:35:51, 33.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6947, 'grad_norm': 0.6976051330566406, 'learning_rate': 0.0002987939698492462, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:50:27.511\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 19, c: 0.00047500000800937414, loss_rr: 0.645, loss_retain: 0.018, loss=0.645, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:50:33.145\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 19, c: 0.00047500000800937414, loss_rr: 0.731, loss_retain: 0.020, loss=0.730, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:50:38.784\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 19, c: 0.00047500000800937414, loss_rr: 0.618, loss_retain: 0.015, loss=0.618, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:50:44.438\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 19, c: 0.00047500000800937414, loss_rr: 0.708, loss_retain: 0.019, loss=0.708, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:50:50.094\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 19, c: 0.00047500000800937414, loss_rr: 0.639, loss_retain: 0.013, loss=0.639, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:50:55.753\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 19, c: 0.00047500000800937414, loss_rr: 0.653, loss_retain: 0.000, loss=0.653, mask_desired: 0.000\u001b[0m\n",
      "  1%|          | 19/2000 [10:29<18:36:34, 33.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6654, 'grad_norm': 0.9397184252738953, 'learning_rate': 0.00029864321608040196, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:51:01.423\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 20, c: 0.0005000000237487257, loss_rr: 0.000, loss_retain: 0.023, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:51:07.056\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 20, c: 0.0005000000237487257, loss_rr: 0.615, loss_retain: 0.022, loss=0.615, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:51:12.705\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 20, c: 0.0005000000237487257, loss_rr: 0.594, loss_retain: 0.022, loss=0.594, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:51:18.364\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 20, c: 0.0005000000237487257, loss_rr: 0.579, loss_retain: 0.022, loss=0.578, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:51:24.012\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 20, c: 0.0005000000237487257, loss_rr: 0.662, loss_retain: 0.020, loss=0.662, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:51:29.670\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 20, c: 0.0005000000237487257, loss_rr: 0.626, loss_retain: 0.000, loss=0.626, mask_desired: 0.000\u001b[0m\n",
      "  1%|          | 20/2000 [11:03<18:37:04, 33.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5125, 'grad_norm': 1.075516700744629, 'learning_rate': 0.00029849246231155777, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:51:35.344\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 21, c: 0.0005249999812804163, loss_rr: 0.527, loss_retain: 0.000, loss=0.527, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:51:41.003\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 21, c: 0.0005249999812804163, loss_rr: 0.551, loss_retain: 0.026, loss=0.551, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:51:46.642\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 21, c: 0.0005249999812804163, loss_rr: 0.580, loss_retain: 0.027, loss=0.580, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:51:52.291\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 21, c: 0.0005249999812804163, loss_rr: 0.545, loss_retain: 0.028, loss=0.545, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:51:57.934\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 21, c: 0.0005249999812804163, loss_rr: 0.564, loss_retain: 0.026, loss=0.564, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:52:03.583\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 21, c: 0.0005249999812804163, loss_rr: 0.602, loss_retain: 0.028, loss=0.602, mask_desired: 0.750\u001b[0m\n",
      "  1%|          | 21/2000 [11:37<18:37:08, 33.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5615, 'grad_norm': 0.9591206312179565, 'learning_rate': 0.0002983417085427135, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:52:09.222\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 22, c: 0.0005499999970197678, loss_rr: 0.523, loss_retain: 0.030, loss=0.522, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:52:14.872\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 22, c: 0.0005499999970197678, loss_rr: 0.498, loss_retain: 0.031, loss=0.497, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:52:20.509\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 22, c: 0.0005499999970197678, loss_rr: 0.000, loss_retain: 0.032, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:52:26.138\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 22, c: 0.0005499999970197678, loss_rr: 0.515, loss_retain: 0.031, loss=0.515, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:52:31.779\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 22, c: 0.0005499999970197678, loss_rr: 0.494, loss_retain: 0.031, loss=0.494, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:52:37.429\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 22, c: 0.0005499999970197678, loss_rr: 0.498, loss_retain: 0.031, loss=0.498, mask_desired: 0.750\u001b[0m\n",
      "  1%|          | 22/2000 [12:11<18:36:08, 33.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4211, 'grad_norm': 0.8680790066719055, 'learning_rate': 0.00029819095477386933, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:52:43.084\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 23, c: 0.0005750000127591193, loss_rr: 0.499, loss_retain: 0.033, loss=0.498, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:52:48.727\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 23, c: 0.0005750000127591193, loss_rr: 0.462, loss_retain: 0.034, loss=0.462, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:52:54.370\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 23, c: 0.0005750000127591193, loss_rr: 0.466, loss_retain: 0.034, loss=0.466, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:53:00.024\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 23, c: 0.0005750000127591193, loss_rr: 0.472, loss_retain: 0.035, loss=0.472, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:53:05.680\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 23, c: 0.0005750000127591193, loss_rr: 0.470, loss_retain: 0.033, loss=0.469, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:53:11.334\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 23, c: 0.0005750000127591193, loss_rr: 0.479, loss_retain: 0.033, loss=0.479, mask_desired: 0.250\u001b[0m\n",
      "  1%|          | 23/2000 [12:45<18:36:05, 33.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4744, 'grad_norm': 1.3056137561798096, 'learning_rate': 0.00029804020100502514, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:53:16.995\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 24, c: 0.0006000000284984708, loss_rr: 0.429, loss_retain: 0.036, loss=0.428, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:53:22.642\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 24, c: 0.0006000000284984708, loss_rr: 0.471, loss_retain: 0.033, loss=0.470, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:53:28.290\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 24, c: 0.0006000000284984708, loss_rr: 0.445, loss_retain: 0.037, loss=0.445, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:53:33.935\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 24, c: 0.0006000000284984708, loss_rr: 0.450, loss_retain: 0.039, loss=0.450, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:53:39.590\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 24, c: 0.0006000000284984708, loss_rr: 0.435, loss_retain: 0.035, loss=0.435, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:53:45.244\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 24, c: 0.0006000000284984708, loss_rr: 0.439, loss_retain: 0.036, loss=0.439, mask_desired: 0.750\u001b[0m\n",
      "  1%|          | 24/2000 [13:18<18:35:45, 33.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4446, 'grad_norm': 1.1451607942581177, 'learning_rate': 0.0002978894472361809, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:53:50.893\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 25, c: 0.0006249999860301614, loss_rr: 0.432, loss_retain: 0.039, loss=0.432, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:53:56.544\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 25, c: 0.0006249999860301614, loss_rr: 0.434, loss_retain: 0.040, loss=0.433, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:54:02.192\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 25, c: 0.0006249999860301614, loss_rr: 0.416, loss_retain: 0.038, loss=0.416, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:54:07.838\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 25, c: 0.0006249999860301614, loss_rr: 0.431, loss_retain: 0.039, loss=0.431, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:54:13.497\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 25, c: 0.0006249999860301614, loss_rr: 0.438, loss_retain: 0.040, loss=0.437, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:54:19.147\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 25, c: 0.0006249999860301614, loss_rr: 0.444, loss_retain: 0.040, loss=0.444, mask_desired: 0.750\u001b[0m\n",
      "  1%|▏         | 25/2000 [13:52<18:35:28, 33.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.432, 'grad_norm': 0.7832686305046082, 'learning_rate': 0.00029773869346733664, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:54:24.801\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 26, c: 0.0006500000017695129, loss_rr: 0.399, loss_retain: 0.042, loss=0.399, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:54:30.450\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 26, c: 0.0006500000017695129, loss_rr: 0.406, loss_retain: 0.043, loss=0.406, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:54:36.105\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 26, c: 0.0006500000017695129, loss_rr: 0.400, loss_retain: 0.043, loss=0.400, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:54:41.768\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 26, c: 0.0006500000017695129, loss_rr: 0.381, loss_retain: 0.043, loss=0.381, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:54:47.413\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 26, c: 0.0006500000017695129, loss_rr: 0.382, loss_retain: 0.041, loss=0.382, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:54:53.064\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 26, c: 0.0006500000017695129, loss_rr: 0.380, loss_retain: 0.042, loss=0.380, mask_desired: 0.500\u001b[0m\n",
      "  1%|▏         | 26/2000 [14:26<18:35:18, 33.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3913, 'grad_norm': 1.0241844654083252, 'learning_rate': 0.00029758793969849245, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:54:58.729\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 27, c: 0.0006750000175088644, loss_rr: 0.393, loss_retain: 0.043, loss=0.393, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:55:04.396\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 27, c: 0.0006750000175088644, loss_rr: 0.377, loss_retain: 0.044, loss=0.376, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:55:10.058\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 27, c: 0.0006750000175088644, loss_rr: 0.000, loss_retain: 0.045, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:55:15.697\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 27, c: 0.0006750000175088644, loss_rr: 0.405, loss_retain: 0.044, loss=0.404, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:55:21.339\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 27, c: 0.0006750000175088644, loss_rr: 0.381, loss_retain: 0.044, loss=0.381, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:55:26.995\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 27, c: 0.0006750000175088644, loss_rr: 0.000, loss_retain: 0.045, loss=0.000, mask_desired: 1.000\u001b[0m\n",
      "  1%|▏         | 27/2000 [15:00<18:34:53, 33.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2591, 'grad_norm': 0.8636786341667175, 'learning_rate': 0.0002974371859296482, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:55:32.626\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 28, c: 0.000699999975040555, loss_rr: 0.368, loss_retain: 0.048, loss=0.368, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:55:38.292\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 28, c: 0.000699999975040555, loss_rr: 0.367, loss_retain: 0.049, loss=0.367, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:55:43.992\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 28, c: 0.000699999975040555, loss_rr: 0.375, loss_retain: 0.048, loss=0.375, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:55:49.651\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 28, c: 0.000699999975040555, loss_rr: 0.352, loss_retain: 0.000, loss=0.352, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:55:55.316\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 28, c: 0.000699999975040555, loss_rr: 0.366, loss_retain: 0.046, loss=0.366, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:56:00.982\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 28, c: 0.000699999975040555, loss_rr: 0.360, loss_retain: 0.047, loss=0.359, mask_desired: 0.750\u001b[0m\n",
      "  1%|▏         | 28/2000 [15:34<18:35:16, 33.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3645, 'grad_norm': 1.2795997858047485, 'learning_rate': 0.000297286432160804, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:56:06.642\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 29, c: 0.0007249999907799065, loss_rr: 0.365, loss_retain: 0.050, loss=0.364, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:56:12.305\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 29, c: 0.0007249999907799065, loss_rr: 0.383, loss_retain: 0.050, loss=0.382, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:56:17.966\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 29, c: 0.0007249999907799065, loss_rr: 0.355, loss_retain: 0.051, loss=0.355, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:56:23.619\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 29, c: 0.0007249999907799065, loss_rr: 0.347, loss_retain: 0.052, loss=0.347, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:56:29.281\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 29, c: 0.0007249999907799065, loss_rr: 0.358, loss_retain: 0.051, loss=0.358, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:56:34.958\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 29, c: 0.0007249999907799065, loss_rr: 0.361, loss_retain: 0.051, loss=0.361, mask_desired: 0.500\u001b[0m\n",
      "  1%|▏         | 29/2000 [16:08<18:35:08, 33.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3611, 'grad_norm': 3.3233532905578613, 'learning_rate': 0.00029713567839195976, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:56:40.615\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 30, c: 0.000750000006519258, loss_rr: 0.352, loss_retain: 0.057, loss=0.351, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:56:46.279\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 30, c: 0.000750000006519258, loss_rr: 0.346, loss_retain: 0.056, loss=0.346, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:56:51.946\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 30, c: 0.000750000006519258, loss_rr: 0.335, loss_retain: 0.057, loss=0.335, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:56:57.597\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 30, c: 0.000750000006519258, loss_rr: 0.337, loss_retain: 0.055, loss=0.336, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:57:03.252\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 30, c: 0.000750000006519258, loss_rr: 0.352, loss_retain: 0.055, loss=0.352, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:57:08.914\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 30, c: 0.000750000006519258, loss_rr: 0.335, loss_retain: 0.057, loss=0.335, mask_desired: 0.750\u001b[0m\n",
      "  2%|▏         | 30/2000 [16:42<18:34:36, 33.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3427, 'grad_norm': 1.471731185913086, 'learning_rate': 0.0002969849246231155, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:57:14.574\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 31, c: 0.0007750000222586095, loss_rr: 0.342, loss_retain: 0.059, loss=0.342, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:57:20.235\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 31, c: 0.0007750000222586095, loss_rr: 0.323, loss_retain: 0.056, loss=0.323, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:57:25.897\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 31, c: 0.0007750000222586095, loss_rr: 0.330, loss_retain: 0.059, loss=0.329, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:57:31.566\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 31, c: 0.0007750000222586095, loss_rr: 0.328, loss_retain: 0.058, loss=0.327, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:57:37.230\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 31, c: 0.0007750000222586095, loss_rr: 0.348, loss_retain: 0.058, loss=0.347, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:57:42.894\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 31, c: 0.0007750000222586095, loss_rr: 0.332, loss_retain: 0.058, loss=0.332, mask_desired: 0.250\u001b[0m\n",
      "  2%|▏         | 31/2000 [17:16<18:34:31, 33.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3334, 'grad_norm': 1.5648552179336548, 'learning_rate': 0.0002968341708542713, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:57:48.571\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 32, c: 0.0007999999797903001, loss_rr: 0.323, loss_retain: 0.059, loss=0.323, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:57:54.241\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 32, c: 0.0007999999797903001, loss_rr: 0.323, loss_retain: 0.061, loss=0.323, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:57:59.910\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 32, c: 0.0007999999797903001, loss_rr: 0.323, loss_retain: 0.059, loss=0.323, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:58:05.557\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 32, c: 0.0007999999797903001, loss_rr: 0.321, loss_retain: 0.058, loss=0.321, mask_desired: 0.750\u001b[0m\n",
      "\u001b[32m2024-06-10 07:58:11.208\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 32, c: 0.0007999999797903001, loss_rr: 0.310, loss_retain: 0.056, loss=0.309, mask_desired: 0.500\u001b[0m\n",
      "\u001b[32m2024-06-10 07:58:16.866\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 32, c: 0.0007999999797903001, loss_rr: 0.324, loss_retain: 0.054, loss=0.324, mask_desired: 0.250\u001b[0m\n",
      "  2%|▏         | 32/2000 [17:50<18:34:00, 33.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3204, 'grad_norm': 1.7377934455871582, 'learning_rate': 0.00029668341708542713, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-10 07:58:22.537\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 33, c: 0.0008249999955296516, loss_rr: 0.309, loss_retain: 0.000, loss=0.309, mask_desired: 0.000\u001b[0m\n",
      "\u001b[32m2024-06-10 07:58:28.213\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 33, c: 0.0008249999955296516, loss_rr: 0.308, loss_retain: 0.060, loss=0.307, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:58:33.875\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 33, c: 0.0008249999955296516, loss_rr: 0.316, loss_retain: 0.059, loss=0.315, mask_desired: 0.250\u001b[0m\n",
      "\u001b[32m2024-06-10 07:58:39.540\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompute_loss\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1msteps: 33, c: 0.0008249999955296516, loss_rr: 0.311, loss_retain: 0.061, loss=0.310, mask_desired: 0.750\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 110\u001b[0m\n\u001b[1;32m     89\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CustomSFTTrainer(\n\u001b[1;32m     90\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     91\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\u001b[39;00m\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    109\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# silence the warnings. Please re-enable for inference!\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:440\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 440\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/transformers/trainer.py:3250\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3248\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3250\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:2130\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2129\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[1;32m   2132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO change the loss function!\n",
    "# we need to modify the forward pass, so that it returns a different loss function\n",
    "# but to calculate this we will need to residuals now, and as they werre\n",
    "# loss_bad = mse(repr_current, repr_target)\n",
    "\n",
    "# from transformers import SFTTrainer\n",
    "from trl.trainer import SFTTrainer, SFTConfig\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from adapter_overseer.helpers.torch_helpers import clear_mem, switch\n",
    "from adapter_overseer.helpers.scores import select_choices\n",
    "\n",
    "class CustomSFTTrainer(SFTTrainer):\n",
    "    \"\"\"\n",
    "    Custom SFTTrainer that orthoganalizes the repr of bad examples, and retains good repr of examples\n",
    "\n",
    "    See: https://arxiv.org/pdf/2406.04313\n",
    "\n",
    "    args:\n",
    "        collection_layers: list of baukit layer names to collect\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, collection_layers: list, alpha=0.1, **kwargs):\n",
    "        super(CustomSFTTrainer, self).__init__(*args, **kwargs)\n",
    "        self.collection_layers = collection_layers\n",
    "        self.alpha = alpha\n",
    "        self.total_steps = self.args.max_steps\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):       \n",
    "\n",
    "        batch = {'input_ids': inputs['input_ids'], 'attention_mask': inputs['attention_mask']}\n",
    "\n",
    "        # collect the residuals of the model\n",
    "        with model.disable_adapter():\n",
    "            orig_outputs = model(**batch, output_hidden_states=True)\n",
    "        outputs = model(**batch, output_hidden_states=True)\n",
    "\n",
    "        def collect_hs(hidden_states):\n",
    "            \"\"\"The residual stream is the diff of the hs.\"\"\"\n",
    "            hs = [hidden_states[i] for i in self.collection_layers]\n",
    "            return rearrange(hs, 'l b t h -> b l t h').diff(1)\n",
    "\n",
    "        rep_adapt = collect_hs(outputs.hidden_states)\n",
    "        rep_orig = collect_hs(orig_outputs.hidden_states)\n",
    "\n",
    "        # so now we have a mixed batch of good and bad outputs\n",
    "        # get probs of each choice\n",
    "        # compare to labels to seperate into good and bad\n",
    "        choice_ids = inputs['choice_ids'].detach().cpu().long()\n",
    "        # label_instructed = inputs['label_true'] ^ inputs['instructed_to_lie']\n",
    "        label_true = inputs['label_true']\n",
    "\n",
    "        # does the underlying model get it right or wrong?\n",
    "        end_logits = orig_outputs[\"logits\"][:, -1]\n",
    "        probs = torch.softmax(end_logits, -1)\n",
    "        choice_probs = select_choices(probs, choice_ids).sum(2)\n",
    "        binary_ans = choice_probs[:, 1] / (choice_probs.sum(1) + 1e-12)\n",
    "        correct_truth_telling = switch(binary_ans, label_true)\n",
    "        # correct_instruction_following = switch(binary_ans, label_instructed)\n",
    "\n",
    "        mask_desired = correct_truth_telling>0.5\n",
    "\n",
    "\n",
    "        # get coeffecient\n",
    "        steps = self.state.global_step + 1\n",
    "        c = torch.tensor(self.alpha * steps / (2 * self.total_steps)).to(rep_orig.dtype)\n",
    "        loss_retain = F.mse_loss(rep_orig, rep_adapt, reduction='none' )[mask_desired]\n",
    "        if loss_retain.numel() == 0:\n",
    "            loss_retain = 0\n",
    "        else:\n",
    "            loss_retain = loss_retain.mean()\n",
    "        loss_rr = F.relu(F.cosine_similarity(rep_orig, rep_adapt, dim=1))[~mask_desired]\n",
    "        if loss_rr.numel() == 0:\n",
    "            loss_rr = 0\n",
    "        else:\n",
    "            loss_rr = loss_rr.mean()\n",
    "        loss = loss_rr * (1 - c) + c * loss_retain\n",
    "        loss = loss\n",
    "        logger.debug(f\"steps: {steps}, c: {c}, loss_rr: {loss_rr:2.3f}, loss_retain: {loss_retain:2.3f}, loss={loss:2.3f}, mask_desired: {(mask_desired*1.0).mean():2.3f}\")\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "\n",
    "# TODO make sure that multiple cols get passed into trainer\n",
    "ds = ds_tokens.select_columns(['label_true', 'label_instructed' ,'instructed_to_lie', 'input_ids', 'attention_mask', 'choice_ids'])\n",
    "\n",
    "import transformers\n",
    "\n",
    "# see https://github.com/huggingface/trl/blob/main/trl/trainer/sft_trainer.py#L58\n",
    "trainer = CustomSFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=ds,\n",
    "    collection_layers=[10, 20],\n",
    "    # max_seq_length=cfg.max_length,\n",
    "    args=SFTConfig(\n",
    "        # see https://github.com/huggingface/trl/blob/main/trl/trainer/sft_config.py#L21\n",
    "        max_seq_length=cfg.max_length,\n",
    "        per_device_train_batch_size=4, # 18GB/24GB\n",
    "        gradient_accumulation_steps=6, # we want to accumulate the gradients to make the batch size larger, so we have sufficient examples of good and bad behaviour to learn from\n",
    "        warmup_steps=10,\n",
    "        max_steps=2000,\n",
    "        learning_rate=3e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        output_dir=\"outputs\",\n",
    "        remove_unused_columns=False,\n",
    "    ),\n",
    "    # data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b0cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "model.save_pretrained(\"../outputs/hs_adapter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec82d4d8",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78d278b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'mc1_targets', 'mc2_targets'],\n",
       "    num_rows: 817\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# multiple_choice\n",
    "from torch.utils.data import DataLoader\n",
    "# dataset = load_dataset(\"truthfulqa/truthful_qa\", \"multiple_choice\")\n",
    "\n",
    "# HACK it was stalling for hours, so I loaded it locally\n",
    "dataset = load_dataset(\"../data/truthful_qa\")['validation']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6c19b517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 817/817 [00:00<00:00, 6091.51 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(row)\n",
    "\n",
    "def format_prompt(row):\n",
    "    prompt = f\"Q: {row['question']}\\n\"\n",
    "    for i, choice in enumerate(row['mc1_targets']['choices']):\n",
    "        prompt += f\"{i+1}. {choice}\\n\"\n",
    "\n",
    "    choices = [str(i) for i in range(len(row['mc1_targets']['labels']))]\n",
    "    return {'text': prompt, \n",
    "            'label': [np.argmax(row['mc1_targets']['labels'])],\n",
    "            'choices': choices,\n",
    "            'num_choices': len(choices),\n",
    "            }\n",
    "\n",
    "dataset1 = dataset.map(format_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d5224624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(r['labels']) for r in dataset['mc1_targets']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a86edd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 605, 806, 717]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get our choice ids\n",
    "choices = [str(i) for i in range(13)]\n",
    "choice_ids = [tokenizer(c, add_special_tokens=False).input_ids[0] for c in choices]\n",
    "choice_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b06168d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 817/817 [00:00<00:00, 4213.33 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'attention_mask', 'num_choices'],\n",
       "    num_rows: 817\n",
       "})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def tokenization(example):\n",
    "    o = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=cfg.max_length, return_tensors=\"pt\")\n",
    "    return o\n",
    "\n",
    "dataset2 = dataset1.map(tokenization, batched=True).select_columns([ 'label', 'input_ids', 'attention_mask', \n",
    "                                                                    'num_choices'\n",
    "                                                                    ]).with_format(\"torch\")\n",
    "dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "01df258a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "  1%|          | 2/205 [00:12<20:23,  6.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[168], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mdisable_adapter():\n\u001b[1;32m     13\u001b[0m     out_base \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m---> 14\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m])):\n\u001b[1;32m     17\u001b[0m     n \u001b[38;5;241m=\u001b[39m b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_choices\u001b[39m\u001b[38;5;124m'\u001b[39m][j]\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:822\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 822\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:810\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/peft/peft_model.py:642\u001b[0m, in \u001b[0;36mPeftModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    641\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m--> 642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/accelerate/hooks.py:167\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/accelerate/hooks.py:380\u001b[0m, in \u001b[0;36mAlignDevicesHook.post_forward\u001b[0;34m(self, module, output)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio_same_device \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:186\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[0;32m--> 186\u001b[0m         {\n\u001b[1;32m    187\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking, skip_keys\u001b[38;5;241m=\u001b[39mskip_keys)\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    189\u001b[0m         }\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:187\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[1;32m    186\u001b[0m         {\n\u001b[0;32m--> 187\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    189\u001b[0m         }\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/elk/adapters_can_monitor_lies/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:158\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    156\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# https://github.dev/sylinrl/TruthfulQA/blob/fdd8ad1c0d00a478cf8b0bb41a3ad8378c16293b/truthfulqa/models.py#L311\n",
    "\n",
    "\n",
    "probs = []\n",
    "base_probs = []\n",
    "\n",
    "dl = DataLoader(\n",
    "    dataset2, batch_size=4, num_workers=0)\n",
    "for b in tqdm(dl):\n",
    "    inputs = {'input_ids': b['input_ids'], 'attention_mask': b['attention_mask']}\n",
    "    with torch.no_grad():\n",
    "        with model.disable_adapter():\n",
    "            out_base = model(**inputs)\n",
    "        out = model(**inputs)\n",
    "\n",
    "        for j in range(len(out[\"logits\"])):\n",
    "            n = b['num_choices'][j]\n",
    "            b_choice_ids = choice_ids[:n]\n",
    "            label = b['label'][j, 0]\n",
    "\n",
    "            choice_probs_base = out_base[\"logits\"][j, -1, b_choice_ids].softmax(dim=-1)\n",
    "            choice_probs = out[\"logits\"][j, -1, b_choice_ids].softmax(dim=-1)\n",
    "            prob = choice_probs[label].item()\n",
    "            prob_base = choice_probs_base[label].item()\n",
    "            probs.append(prob)\n",
    "            base_probs.append(prob_base)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7c7cca00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0395, 0.5892, 0.2594, 0.0377, 0.0161, 0.0065, 0.0130, 0.0232, 0.0068,\n",
       "        0.0022, 0.0064])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choice_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "33f4a04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0395, 0.5892, 0.2594, 0.0377, 0.0161, 0.0065, 0.0130, 0.0232, 0.0068,\n",
       "        0.0022, 0.0064])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choice_probs_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c007c690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = ((torch.tensor(probs)>0.5)*1.0).mean()\n",
    "base_acc = ((torch.tensor(base_probs)>0.5)*1.0).mean()\n",
    "acc, base_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9be360a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0139), tensor(0.0139))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_correct = torch.tensor(probs).mean()\n",
    "prob_base_correct = torch.tensor(base_probs).mean()\n",
    "prob_correct, prob_base_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e21ba4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 13])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8d595f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]),\n",
       " 'input_ids': tensor([[128009, 128009, 128009,  ...,   3723,   4273,    627],\n",
       "         [128009, 128009, 128009,  ...,     13,   8494,    627],\n",
       "         [128009, 128009, 128009,  ...,    559,   9949,    627],\n",
       "         [128009, 128009, 128009,  ...,    304,  16759,    627]]),\n",
       " 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1]]),\n",
       " 'num_choices': tensor([4, 5, 4, 4])}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a98d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# import evaluate\n",
    "from transformers import pipeline\n",
    "\n",
    "# accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "dataset_eval = load_dataset(\"EleutherAI/truthful_qa_binary\", split=\"test\")[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b3784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import evaluator\n",
    "from datasets import load_dataset\n",
    "data = load_dataset(\"EleutherAI/truthful_qa_binary\", split=\"validation[:20]\")\n",
    "task_evaluator = evaluator(\"text-classification\")\n",
    "# see https://huggingface.co/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.TextClassificationEvaluator\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    # feature_extractor=feature_extractor,\n",
    "    # device=device,\n",
    ")\n",
    "\n",
    "\n",
    "results = task_evaluator.compute(\n",
    "    pipe,\n",
    "    # tokenizer=tokenizer,\n",
    "    data=data,\n",
    "    metric=\"accuracy\",\n",
    "    input_column=\"question\",\n",
    "    # label_mapping={\"LABEL_0\": 0.0, \"LABEL_1\": 1.0},\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d383d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def preprocess_function(examples):\n",
    "#     return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "# https://huggingface.co/docs/transformers/v4.41.3/en/main_classes/pipelines#pipeline-batching\n",
    "pipe = pipeline(\"text-classification\", device=\"auto\", model=model, tokenizer=tokenizer)\n",
    "batch_size = 4\n",
    "for out in tqdm(pipe(dataset_eval, batch_size=batch_size), total=len(dataset_eval)):\n",
    "    1/0\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b4003d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 8,033,669,120 || trainable%: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6db821a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 8,033,669,120 || trainable%: 0.0000\n"
     ]
    }
   ],
   "source": [
    "with model.disable_adapter():\n",
    "    model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc38fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
